{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72460484",
   "metadata": {},
   "source": [
    "# Transformer 기초내용\n",
    "\n",
    "`-` 이번 내용 : Transformer 전의 RNN 과 관련하여 긴 시퀀스에 대해서 레이어가 깊어져도 학습이 잘 되는 방법론들 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421777d",
   "metadata": {},
   "source": [
    "## ExtendedNeuralGPU\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ExtendedNeuralGPU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
    "        super(ExtendedNeuralGPU, self).__init__()\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(input_dim if i == 0 else hidden_dim, hidden_dim, kernel_size=3, padding=1) for i in range(n_layers)])\n",
    "        self.glu = nn.GLU()\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = self.glu(conv(x))\n",
    "        x = x.mean(dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = ExtendedNeuralGPU(input_dim=10, hidden_dim=20, output_dim=30, n_layers=5)\n",
    "input_seq = torch.rand(32, 10, 50)  # batch_size, input_dim, seq_length\n",
    "output = model(input_seq)\n",
    "print(output.shape)  # Should be (32, 30)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a0edb",
   "metadata": {},
   "source": [
    "## ByteNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f651b7",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ByteNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
    "        super(ByteNet, self).__init__()\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(input_dim if i == 0 else hidden_dim, hidden_dim, kernel_size=3, padding=1, dilation=2**i) for i in range(n_layers)])\n",
    "        self.residual_conns = nn.ModuleList([nn.Conv1d(hidden_dim, hidden_dim, kernel_size=1) for _ in range(n_layers)])\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv, res_conn in zip(self.convs, self.residual_conns):\n",
    "            residual = x\n",
    "            x = conv(x)\n",
    "            x = torch.relu(x)\n",
    "            x = res_conn(x) + residual\n",
    "        x = x.mean(dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = ByteNet(input_dim=10, hidden_dim=20, output_dim=30, n_layers=5)\n",
    "input_seq = torch.rand(32, 10, 50)  # batch_size, input_dim, seq_length\n",
    "output = model(input_seq)\n",
    "print(output.shape)  # Should be (32, 30)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e0287a",
   "metadata": {},
   "source": [
    "## ConvS2S (Convolutional Sequence to Sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e13fa89",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvS2S(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, max_seq_len):\n",
    "        super(ConvS2S, self).__init__()\n",
    "        self.embed = nn.Embedding(max_seq_len, input_dim)\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(input_dim if i == 0 else hidden_dim, hidden_dim, kernel_size=3, padding=1) for i in range(n_layers)])\n",
    "        self.glu = nn.GLU()\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        for conv in self.convs:\n",
    "            x = self.glu(conv(x))\n",
    "        x = x.mean(dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = ConvS2S(input_dim=10, hidden_dim=20, output_dim=30, n_layers=5, max_seq_len=50)\n",
    "input_seq = torch.randint(0, 50, (32, 50))  # batch_size, seq_length\n",
    "output = model(input_seq)\n",
    "print(output.shape)  # Should be (32, 30)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace91b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
